---
slug: eiuie
image: <img loading="lazy" src="images/projects/EIUIE/thumbnail.webp" alt="Enhancing Images with Uneven Illumination using Ensemble Learning"/>
title: EIUIE
color: bg-purple-600
tagline: Enhancing Images with Uneven Illumination using Ensemble Learning
url: https://github.com/CodingTil/eiuie
date_range: November 2023
skills: [python, computer vision, pytorch, image processing, git]
filters: [computer vision, pytorch, image processing, git]
coauthors:
  - name: Alexander Mühleisen
    url: https://github.com/AlexanderMuehleisen
report: public/eiuie.pdf
---
# Overview
While studying abroad at the University of Stavanger, my colleague Alexander Mühleisen and I got the chance to dive into a pretty interesting project for our "Image Processing and Computer Vision" course. We chose to tackle the challenge of enhancing images with uneven illumination - a topic that's both tricky and fascinating.

# Motivation
First up, we looked into a few classic methods. There's Unsharp Masking (UM), which basically sharpens the whole image by focusing on the high-frequency details. Then, Retinex algorithms (RTX) try to brighten up darker areas, kind of like how our eyes do. And don't forget Homomorphic Filtering (HF) – this one's all about tweaking the image's lighting and colors by playing around with frequencies.

# Approach
Each of these methods has its own strengths and weak spots. So, we thought, why not mix them up using ensemble learning? The goal was to see if combining them could give us even better results in different scenarios. To do this, we came up with a fusion network, using a simple three-node perceptron network for each color channel in the HSI color space. The setup of this network is shown in the figure below - here, solid red arrows symbolize the fusion of the hue channels, green dashed arrows the fusion of the saturation channels and blue dotted arrows the fusion of the intensity channels.

<img loading="lazy" src="images/projects/EIUIE/pipeline.webp" alt="Fusion Network"/>

# Training & Evaluation
This fusion method involves 9 trainable parameters, and we trained it using the <a href="https://www.kaggle.com/datasets/soumikrakshit/lol-dataset">LOL Dataset</a>. From our tests, it looks like the fusion method balances out the ups and downs of the three individual techniques. While in some cases, like with RTX, the individual methods could outshine our fusion network, our approach was pretty solid in enhancing image details and brightening up darker areas. Below, we've put together some side-by-side comparisons to show how our fusion network stacks up against each method:

<div class="container mx-auto p-4">
	<div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-5 gap-4">
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/original.webp" alt="Original" class="mx-auto">
			<p class="text-center text-lg font-semibold">Original</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/fusion.webp" alt="Fusion" class="mx-auto">
			<p class="text-center text-lg font-semibold">Fusion</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/um.webp" alt="Unsharp Masking" class="mx-auto">
			<p class="text-center text-lg font-semibold">Unsharp Masking</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/rtx.webp" alt="Retinex" class="mx-auto">
			<p class="text-center text-lg font-semibold">Retinex</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/hf.webp" alt="Homomorphic Filtering" class="mx-auto">
			<p class="text-center text-lg font-semibold">Homomorphic Filtering</p>
		</div>
	</div>
</div>