---
slug: eiuie
image: <img loading="lazy" src="images/projects/EIUIE/thumbnail.webp" alt="Verbesserung von Bildern mit ungleichmäßiger Beleuchtung durch Ensemble-Lernen"/>
title: EIUIE
color: bg-purple-600
tagline: Verbesserung von Bildern mit ungleichmäßiger Beleuchtung durch Ensemble-Lernen
url: https://github.com/CodingTil/eiuie
date_range: November 2023
skills: [python, computer vision, pytorch, image processing, git]
filters: [computer vision, pytorch, image processing, git]
coauthors:
  - name: Alexander Mühleisen
    url: https://github.com/AlexanderMuehleisen
report: public/eiuie.pdf
---
# Übersicht
Während meines Auslandsstudiums an der Universität von Stavanger hatten mein Kollege Alexander Mühleisen und ich die Gelegenheit, an einem ziemlich interessanten Projekt für unseren Kurs "Image Processing and Computer Vision" zu arbeiten. Wir entschieden uns, die Herausforderung der Verbesserung von Bildern mit ungleichmäßiger Beleuchtung anzugehen – ein Thema, das sowohl knifflig als auch faszinierend ist.

# Motivation
Zuerst beschäftigten wir uns mit einigen klassischen Methoden. Da gibt es das Unsharp Masking (UM), das im Grunde das ganze Bild schärft, indem es sich auf die hochfrequenten Details konzentriert. Dann versuchen Retinex-Algorithmen (RTX), dunklere Bereiche aufzuhellen, ähnlich wie unsere Augen. Und nicht zu vergessen, das Homomorphe Filtern (HF) – diese Methode dreht sich darum, die Beleuchtung und Farben des Bildes durch das Spielen mit Frequenzen zu verändern.

# Ansatz
Jede dieser Methoden hat ihre eigenen Stärken und Schwächen. Also dachten wir, warum nicht sie mit Ensemble-Lernen kombinieren? Unser Ziel war es zu sehen, ob wir durch ihre Kombination noch bessere Ergebnisse in verschiedenen Szenarien erzielen könnten. Dafür entwickelten wir ein Fusionsnetzwerk, das für jeden Farbkanal im HSI-Farbraum ein einfaches Drei-Knoten-Perzeptron-Netzwerk verwendet. Die Konfiguration dieses Netzwerks wird in der folgenden Abbildung gezeigt – hier symbolisieren solide rote Pfeile die Fusion der Hue-Kanäle, grün gestrichelte Pfeile die Fusion der Sättigungskanäle und blau gepunktete Pfeile die Fusion der Intensitätskanäle.

<img loading="lazy" src="images/projects/EIUIE/pipeline.webp" alt="Fusionsnetzwerk"/>

# Training & Evaluation
Diese Fusionsmethode beinhaltet 9 trainierbare Parameter, und wir haben sie mit dem <a href="https://www.kaggle.com/datasets/soumikrakshit/lol-dataset">LOL Dataset</a> trainiert. Unsere Tests zeigen, dass die Fusionsmethode die Vor- und Nachteile der drei einzelnen Techniken ausgleicht. In einigen Fällen, wie bei RTX, konnten die einzelnen Methoden unser Fusionsnetzwerk übertreffen, aber unser Ansatz war ziemlich solide darin, Bilddetails zu verbessern und dunklere Bereiche aufzuhellen. Unten haben wir einige Vergleichsbilder zusammengestellt, um zu zeigen, wie unser Fusionsnetzwerk im Vergleich zu den einzelnen Methoden abschneidet:

<div class="container mx-auto p-4">
	<div class="grid grid-cols-1 sm:grid-cols-2 lg:grid-cols-5 gap-4">
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/original.webp" alt="Original" class="mx-auto">
			<p class="text-center text-lg font-semibold">Original</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/fusion.webp" alt="Fusion" class="mx-auto">
			<p class="text-center text-lg font-semibold">Fusion</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/um.webp" alt="Unsharp Masking" class="mx-auto">
			<p class="text-center text-lg font-semibold">Unsharp Masking</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/rtx.webp" alt="Retinex" class="mx-auto">
			<p class="text-center text-lg font-semibold">Retinex</p>
		</div>
		<div class="text-center">
			<img loading="lazy" src="images/projects/EIUIE/hf.webp" alt="Homomorphes Filtern" class="mx-auto">
			<p class="text-center text-lg font-semibold">Homomorphes Filtern</p>
		</div>
	</div>
</div>